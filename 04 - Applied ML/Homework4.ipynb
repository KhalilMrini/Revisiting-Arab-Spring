{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4- Table of Contents\n",
    "\n",
    "### [Task 1. Propensity score matching](#1)\n",
    "- [1.1. A naive analysis](#11)\n",
    "\n",
    "- [1.2. A closer look at the data](#12)\n",
    "\n",
    "- [1.3. A propensity score model](#13)\n",
    "\n",
    "- [1.4. Balancing the dataset via matching](#14)\n",
    "\n",
    "- [1.5. Balancing the groups further](#15)\n",
    "\n",
    "- [1.6. A less naive analysis](#14)\n",
    "\n",
    "\n",
    "### [Task 2. Applied ML](#2)\n",
    "- [2.1. Load data](#21)\n",
    "\n",
    "- [2.2. Train data with random forest](#22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "- [scikit-learn](http://scikit-learn.org/stable/)\n",
    "- pandas\n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Propensity Score Matching <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "### Assignment Instructions\n",
    "In this exercise, you will apply propensity score matching, which we discussed in lecture 5 (\"Observational studies\"), in order to draw conclusions from an observational study.\n",
    "\n",
    "We will work with a by-now classic dataset from Robert LaLonde's study \"Evaluating the Econometric Evaluations of Training Programs\" (1986). The study investigated the effect of a job training program (\"National Supported Work Demonstration\") on the real earnings of an individual, a couple of years after completion of the program. Your task is to determine the effectiveness of the \"treatment\" represented by the job training program.\n",
    "\n",
    "Dataset description\n",
    "\n",
    "- `treat`: 1 if the subject participated in the job training program, 0 otherwise\n",
    "- `age`: the subject's age\n",
    "- `educ`: years of education\n",
    "- `race`: categorical variable with three possible values: Black, Hispanic, or White\n",
    "- `married`: 1 if the subject was married at the time of the training program, 0 otherwise\n",
    "- `nodegree`: 1 if the subject has earned no school degree, 0 otherwise\n",
    "- `re74`: real earnings in 1974 (pre-treatment)\n",
    "- `re75`: real earnings in 1975 (pre-treatment)\n",
    "- `re78`: real earnings in 1978 (outcome)\n",
    "\n",
    "\n",
    "### 1.1. A Naive Analysis<a class=\"anchor\" id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. A closer look at the data<a class=\"anchor\" id=\"12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. A propensity score model<a class=\"anchor\" id=\"13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Balancing the dataset via matching <a class=\"anchor\" id=\"14\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Balancing the groups further <a class=\"anchor\" id=\"15\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. A less naive analysis <a class=\"anchor\" id=\"16\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Swiss Unemployment Rates Analysis - *amstat* dataset <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "### Assignment Instructions\n",
    "\n",
    "We are going to build a classifier of news to directly assign them to 20 news categories. Note that the pipeline that you will build in this exercise could be of great help during your project if you plan to work with text!\n",
    "\n",
    "Load the 20newsgroup dataset. It is, again, a classic dataset that can directly be loaded using sklearn (link).\n",
    "TF-IDF, short for term frequencyâ€“inverse document frequency, is of great help when if comes to compute textual features. Indeed, it gives more importance to terms that are more specific to the considered articles (TF) but reduces the importance of terms that are very frequent in the entire corpus (IDF). Compute TF-IDF features for every article using TfidfVectorizer. Then, split your dataset into a training, a testing and a validation set (10% for validation and 10% for testing). Each observation should be paired with its corresponding label (the article category).\n",
    "\n",
    "Train a random forest on your training set. Try to fine-tune the parameters of your predictor on your validation set using a simple grid search on the number of estimator \"n_estimators\" and the max depth of the trees \"max_depth\". Then, display a confusion matrix of your classification pipeline. Lastly, once you assessed your model, inspect the feature_importances_ attribute of your random forest and discuss the obtained results.\n",
    "\n",
    "### 2.1. Pick a DataSet to analyse <a class=\"anchor\" id=\"21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Choropleth map of Cantonal Unemployment Rates  <a class=\"anchor\" id=\"22\"></a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
